<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech Recognition on iPad</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin: 50px;
        }
        #result {
            margin-top: 20px;
            font-size: 1.2em;
            border: 1px solid #ccc;
            padding: 10px;
            min-height: 50px;
        }
        button {
            font-size: 1em;
            padding: 10px 20px;
            margin-top: 20px;
        }
    </style>
</head>
<body>

    <h1>Speech Recognition for iPad</h1>
    <button id="start">Start Listening</button>
    <p id="result">Your speech will appear here...</p>

    <div>
        <textarea id="log" rows="10" cols="50"></textarea>
    </div>

    <script>
                function log(...msg) {
            const logArea = document.getElementById("log");
            if (logArea) {
                const message = msg.map(arg => typeof arg === 'object' ? JSON.stringify(arg) : arg).join(' ');
                logArea.value += message + "\n";
                logArea.scrollTop = logArea.scrollHeight;
            } else {
                console.log(msg);
            }
                }

        function _setupListeners(recognition, callbacks) {
        const events = [
            'audiostart', 'soundstart', 'speechstart', 
            'speechend', 'soundend', 'audioend', 
            'result', 'nomatch', 'error', 'end'
        ];

        events.forEach(event => {
            if (callbacks[`on${event}`]) {
                recognition[`on${event}`] = callbacks[`on${event}`];
            }
        });
    }

    function setupListeners(recognition) {
        _setupListeners(recognition, {
            onaudiostart: () => log("Audio capturing started."),
            onsoundstart: () => log("Sound detected."),
            onspeechstart: () => log("Speech detected."),
            onspeechend: () => log("Speech has ended."),
            onsoundend: () => log("Sound has stopped."),
            onaudioend: () => log("Audio capturing ended."),
            // onresult: (event) => this.handleResult(event),
            onnomatch: () => log("No speech match found."),
            onerror: (event) => log(`Speech recognition error: ${event.error}`),
            onend: () => log("Speech recognition service has stopped.")
        });
    }

        window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        if ('SpeechRecognition' in window) {
            const recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = true;
            recognition.lang = 'fr-FR';

            setupListeners(recognition);

            recognition.onresult = (event) => {
                const transcript = Array.from(event.results)
                    .map(result => result[0].transcript)
                    .join('');
                document.getElementById('result').innerText = transcript;
            };

            recognition.addEventListener("audiostart", () => {
                log("Audio capturing started");
            });

            recognition.onerror = (event) => {
                log('ERROR', 'Speech recognition error:', event.error);
                alert('Speech recognition error: ' + event.error);
            };

            document.getElementById('start').addEventListener('click', () => {
                recognition.start();
            });
        } else {
            alert("Your browser does not support Speech Recognition.");
        }
    </script>

</body>
</html>
